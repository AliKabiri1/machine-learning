{"cells":[{"cell_type":"markdown","metadata":{},"source":["# importing neccessery library"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:40:31.020437Z","iopub.status.busy":"2023-10-10T17:40:31.020150Z","iopub.status.idle":"2023-10-10T17:40:31.126141Z","shell.execute_reply":"2023-10-10T17:40:31.124867Z","shell.execute_reply.started":"2023-10-10T17:40:31.020417Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n","from sklearn.model_selection import train_test_split,cross_val_score\n","from sklearn.compose import ColumnTransformer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score,confusion_matrix"]},{"cell_type":"markdown","metadata":{},"source":["# 1.reading dataset"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:37:19.191905Z","iopub.status.busy":"2023-10-10T17:37:19.191480Z","iopub.status.idle":"2023-10-10T17:37:19.218462Z","shell.execute_reply":"2023-10-10T17:37:19.217252Z","shell.execute_reply.started":"2023-10-10T17:37:19.191886Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('IRIS.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T16:42:18.241598Z","iopub.status.busy":"2023-10-10T16:42:18.241228Z","iopub.status.idle":"2023-10-10T16:42:18.258818Z","shell.execute_reply":"2023-10-10T16:42:18.257452Z","shell.execute_reply.started":"2023-10-10T16:42:18.241575Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal-length</th>\n","      <th>sepal-width</th>\n","      <th>petal-length</th>\n","      <th>petal-width</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal-length  sepal-width  petal-length  petal-width      species\n","0           5.1          3.5           1.4          0.2  Iris-setosa\n","1           4.9          3.0           1.4          0.2  Iris-setosa\n","2           4.7          3.2           1.3          0.2  Iris-setosa\n","3           4.6          3.1           1.5          0.2  Iris-setosa\n","4           5.0          3.6           1.4          0.2  Iris-setosa"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 2.find each feature data type"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T16:43:22.503390Z","iopub.status.busy":"2023-10-10T16:43:22.503109Z","iopub.status.idle":"2023-10-10T16:43:22.523609Z","shell.execute_reply":"2023-10-10T16:43:22.522702Z","shell.execute_reply.started":"2023-10-10T16:43:22.503368Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150 entries, 0 to 149\n","Data columns (total 5 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   sepal-length  150 non-null    float64\n"," 1   sepal-width   150 non-null    float64\n"," 2   petal-length  150 non-null    float64\n"," 3   petal-width   150 non-null    float64\n"," 4   species       150 non-null    object \n","dtypes: float64(4), object(1)\n","memory usage: 6.0+ KB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["## **from the above output we can understand the 'species' column needs a category encoding and as the dataset doesn't have a lot of feature it's be good to use one-hot encoder**"]},{"cell_type":"markdown","metadata":{},"source":["# 3.finding data statics:"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T16:52:15.144319Z","iopub.status.busy":"2023-10-10T16:52:15.143981Z","iopub.status.idle":"2023-10-10T16:52:15.160921Z","shell.execute_reply":"2023-10-10T16:52:15.159995Z","shell.execute_reply.started":"2023-10-10T16:52:15.144298Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal-length</th>\n","      <th>sepal-width</th>\n","      <th>petal-length</th>\n","      <th>petal-width</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5.843333</td>\n","      <td>3.054000</td>\n","      <td>3.758667</td>\n","      <td>1.198667</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.828066</td>\n","      <td>0.433594</td>\n","      <td>1.764420</td>\n","      <td>0.763161</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.300000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5.100000</td>\n","      <td>2.800000</td>\n","      <td>1.600000</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5.800000</td>\n","      <td>3.000000</td>\n","      <td>4.350000</td>\n","      <td>1.300000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.400000</td>\n","      <td>3.300000</td>\n","      <td>5.100000</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>7.900000</td>\n","      <td>4.400000</td>\n","      <td>6.900000</td>\n","      <td>2.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       sepal-length  sepal-width  petal-length  petal-width\n","count    150.000000   150.000000    150.000000   150.000000\n","mean       5.843333     3.054000      3.758667     1.198667\n","std        0.828066     0.433594      1.764420     0.763161\n","min        4.300000     2.000000      1.000000     0.100000\n","25%        5.100000     2.800000      1.600000     0.300000\n","50%        5.800000     3.000000      4.350000     1.300000\n","75%        6.400000     3.300000      5.100000     1.800000\n","max        7.900000     4.400000      6.900000     2.500000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["# 4.checking for class imbalance and missing value and outliers"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:13:54.436937Z","iopub.status.busy":"2023-10-10T17:13:54.436620Z","iopub.status.idle":"2023-10-10T17:13:54.443104Z","shell.execute_reply":"2023-10-10T17:13:54.442281Z","shell.execute_reply.started":"2023-10-10T17:13:54.436917Z"},"trusted":true},"outputs":[{"data":{"text/plain":["species\n","Iris-setosa        50\n","Iris-versicolor    50\n","Iris-virginica     50\n","Name: count, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data['species'].value_counts()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:16:24.735636Z","iopub.status.busy":"2023-10-10T17:16:24.735178Z","iopub.status.idle":"2023-10-10T17:16:24.742667Z","shell.execute_reply":"2023-10-10T17:16:24.741975Z","shell.execute_reply.started":"2023-10-10T17:16:24.735617Z"},"trusted":true},"outputs":[{"data":{"text/plain":["sepal-length    0\n","sepal-width     0\n","petal-length    0\n","petal-width     0\n","species         0\n","dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["## checking for outliers using z-score"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:27:21.843572Z","iopub.status.busy":"2023-10-10T17:27:21.843126Z","iopub.status.idle":"2023-10-10T17:27:21.852503Z","shell.execute_reply":"2023-10-10T17:27:21.851452Z","shell.execute_reply.started":"2023-10-10T17:27:21.843542Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [sepal-length, sepal-width, petal-length, petal-width]\n","Index: []\n"]}],"source":["#calculate z-score for each column of data\n","z_scores = np.abs((data - data.mean())/data.std(ddof=0))\n","#define a threshold z-score value beyond which data point is considered an outlier\n","threshold = 3.5\n","#Identify outliers in each column\n","outliers = data[(z_scores>threshold).any(axis=1)]\n","#printing outliers\n","print(outliers)"]},{"cell_type":"markdown","metadata":{},"source":["there was no outlier in the dataset :)"]},{"cell_type":"markdown","metadata":{},"source":["# spliting the dataset"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:38:34.521799Z","iopub.status.busy":"2023-10-10T17:38:34.521250Z","iopub.status.idle":"2023-10-10T17:38:34.529817Z","shell.execute_reply":"2023-10-10T17:38:34.529181Z","shell.execute_reply.started":"2023-10-10T17:38:34.521775Z"},"trusted":true},"outputs":[],"source":["X = data.drop('species',axis=1)\n","y = data['species']\n","X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y)\n","\n","categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n","numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n","my_cols = categorical_cols + numerical_cols\n","X_train = X_train_full[my_cols].copy()\n","X_valid = X_valid_full[my_cols].copy()"]},{"cell_type":"markdown","metadata":{},"source":["# preprocessing and category encoding with piplines\n","in the following we are going to scale the numerical data and encode the 'species' column using one hot encoding using pipelines.\n","## how to choose:\n","based on the information from step 2 and 3 we conclude the best scaler for this dataset is standard scaler and as the dataset doesn't have a lot of features the one hot encoder are the best choises."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:43:12.256447Z","iopub.status.busy":"2023-10-10T17:43:12.256145Z","iopub.status.idle":"2023-10-10T17:43:12.262472Z","shell.execute_reply":"2023-10-10T17:43:12.261157Z","shell.execute_reply.started":"2023-10-10T17:43:12.256426Z"},"trusted":true},"outputs":[],"source":["#define a pipline for scaling\n","numerical_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler())\n","])\n","#define a pipline for encoding\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder())\n","])\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","#defining the logistic regression model\n","model = LogisticRegression()\n","#using pipline to run the model\n","pipeline = Pipeline(steps=[\n","    ('preprocessor',preprocessor),\n","    ('model',model)\n","    ])"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T17:44:04.700231Z","iopub.status.busy":"2023-10-10T17:44:04.699946Z","iopub.status.idle":"2023-10-10T17:44:04.728763Z","shell.execute_reply":"2023-10-10T17:44:04.727895Z","shell.execute_reply.started":"2023-10-10T17:44:04.700211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["accurancy: 0.9210526315789473\n"]}],"source":["#finding the model accuracy\n","pipeline.fit(X_train,y_train)\n","pred = pipeline.predict(X_valid)\n","score = accuracy_score(y_valid, pred)\n","print('accurancy:', score)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
